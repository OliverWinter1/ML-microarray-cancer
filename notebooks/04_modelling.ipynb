{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "18a1648e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "X = pd.read_parquet(\"data/X.parquet\")\n",
    "y = pd.read_csv(\"data/y.csv\")\n",
    "\n",
    "y.rename(columns={'Unnamed: 0': 'Sample',\n",
    "    'characteristics_ch1.4.er status': 'Er_status'}, inplace=True)\n",
    "X.rename(columns={'Unnamed: 0': 'Sample'},inplace=True)\n",
    "\n",
    "y.set_index('Sample', inplace=True)\n",
    "\n",
    "assert X.index.equals(y.index)\n",
    "\n",
    "y = y.iloc[:, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e858f6f6",
   "metadata": {},
   "source": [
    "Start building the pipelines for the model, first divide the data in training and testing. Try to makee sure that both groups of data have similar Er+ and Er- ratios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f95a873d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train: (505, 60607) Test: (127, 60607)\n",
      "\n",
      "Class balance (train):\n",
      "Er_status\n",
      "1.0    0.760396\n",
      "0.0    0.239604\n",
      "Name: proportion, dtype: float64\n",
      "\n",
      "Class balance (test):\n",
      "Er_status\n",
      "1.0    0.76378\n",
      "0.0    0.23622\n",
      "Name: proportion, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, train_size=0.8, stratify=y, test_size=0.2, random_state=1)\n",
    "\n",
    "print(\"Train:\", X_train.shape, \"Test:\", X_test.shape)\n",
    "print(\"\")\n",
    "print(\"Class balance (train):\")\n",
    "print(y_train.value_counts(normalize=True))\n",
    "print(\"\")\n",
    "print(\"Class balance (test):\")\n",
    "print(y_test.value_counts(normalize=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "35056c13",
   "metadata": {},
   "source": [
    "First, set a baseline for the model using dummy classifer. \n",
    "Stratified folding makes sure the cross validation groups are balanced when splitting.\n",
    "We will use ROC-AUC as our model performence metric."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e67a3d99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.5\n"
     ]
    }
   ],
   "source": [
    "from sklearn.dummy import DummyClassifier\n",
    "from sklearn.model_selection import cross_val_score, StratifiedKFold\n",
    "\n",
    "cross_val = StratifiedKFold(n_splits=5, shuffle=True, random_state=1)\n",
    "\n",
    "dummy = DummyClassifier(strategy=\"most_frequent\")\n",
    "dummy_roc_auc = cross_val_score(dummy, X_train, y_train, cv = cross_val, scoring = \"roc_auc\")\n",
    "\n",
    "print(dummy_roc_auc.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81885407",
   "metadata": {},
   "source": [
    "The dummy shows an output of 0.5 which is what is expected in ROC_AUC\n",
    "A basic logistic regression model should improve this score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b3b94ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9405012531328321\n"
     ]
    }
   ],
   "source": [
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "log_reg = Pipeline(steps=[(\"Scaler\", StandardScaler()),\n",
    "                         (\"model\", LogisticRegression(max_iter=10000, class_weight=\"balanced\", random_state = 1))])\n",
    "\n",
    "log_roc_auc = cross_val_score(log_reg, X_train, y_train, cv = cross_val, scoring = \"roc_auc\")\n",
    "\n",
    "print(log_roc_auc.mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b81fb9b3",
   "metadata": {},
   "source": [
    "Test this model on the test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fac3636e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9573883161512028"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "log_reg.fit(X_train, y_train)\n",
    "y_prob = log_reg.predict_proba(X_test)[:, 1]\n",
    "roc_auc_score(y_test, y_prob)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
